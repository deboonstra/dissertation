---
output: html_document
---

# Simulations for `norm_gls_sim.R`
```{r loading packages, include = FALSE}
R <- list.files(path = "./simulations/R", pattern = "*.R", full.names = TRUE)
sapply(R, source, .GlobalEnv)
library(knitr)
library(kableExtra)
```

## Setting

### Data
Following Wang *et al.* (2012) with one-hundred replications, the correlated normal responses are generated from the model $$y_{ij} = \mathbf{X}_{ij}^{\top}\boldsymbol{\beta} + \varepsilon_{ij},$$ where $i = 1, \ldots, 200,$ $j = 1, \ldots, 4,$ $\mathbf{X}_{ij} = (x_{ij, 1}, \ldots, x_{ij, 6})^{\top},$ and $\boldsymbol{\beta} = (2.0, 3.0, 0.5, 0.0, 0.0, 0.0)^{\top}.$

- For the covariates,
    - $x_{ij,1}$ was generated from the Bernoulli(0.5) distribution, and 
    - $x_{ij,2}$ to $x_{ij,6}$ from the multivariate normal distribution with mean 0 and an AR(1) covariance matrix with marginal variance 1 and auto-correlation coefficient 0.5.
- The random errors $(\varepsilon_{i1}, \ldots, \varepsilon_{i4})^{\top}$ are generated from the multivariate normal distribution with marginal mean o, marginal variance 1, and an exchangeable correlation matrix with $\rho = 0.5$.

### Transformation of the response
After the data was simulated, the response, $\mathbf{y},$ was transformed by:

1. fitting a fully saturated model with an unstructured working correlation matrix,
2. calculating $\mathbf{V}_{i} = \phi \mathbf{A}_{i}^{1/2}\mathbf{R}_{i}(\boldsymbol{\alpha})\mathbf{A}_{i}^{1/2}$ and finding $\mathbf{V}_{i}^{-1/2}$, and
3. obtaining $\mathbf{y}^{*} = \mathbf{V}_{i}^{-1/2}\mathbf{y}$.

### Best subsets
Using the transformed response, the all $2^6 - 1 = 63$ subsets of the full saturated model were fit using either an independence, exchangeable, or AR(1) working correlation structure. Then, the model resulting in the minimum QIC value was selected as the best fitting model.

```{r, echo = FALSE}
nsims <- 100L
beta <- c(2.0, 3.0, 0.5, 0.0, 0.0, 0.0)
w <- which(beta != 0)
l <- length(w)
```


## Results
The simulations results are stored in:
```{r loading sim res}
load("./simulations/outputs/norm_gls_sim/norm_gls_sim.RData")
```

### QIC across the simulations
Now for each of the models with the minimum QIC, the information criterion value will be broken into its parts to see what is impacting the selection process. Additionally, this provides a look at the stability of the information criterion across the simulations. QIC was devised by Pan (2001a), which assumed independence among the response to allow the use of the quasi-likelihood framework. Thus,
$$
QIC = -2 * \text{quasi-likelihood} + 2tr\left(\widehat{\boldsymbol{\Omega}}_{I}\widehat{\mathbf{V}}_{R}\right),
$$
where $-2 * \text{quasi-likelihood}$ is the goodness-of-fit term (GOF) and $2tr\left(\widehat{\boldsymbol{\Omega}}_{I}\widehat{\mathbf{V}}_{R}\right)$ is the penalty term.
```{r, echo = FALSE}
qic_indp <- sapply(res_indp, function(x) {x$qic_min}, simplify = TRUE)
qic_ar1 <- sapply(res_ar1, function(x) {x$qic_min}, simplify = TRUE)
qic_cs <- sapply(res_cs, function(x) {x$qic_min}, simplify = TRUE)

plot(
    x = seq_len(nsims), y = qic_indp,
    ylim = c(1700, 4800),
    xlab = "Index", ylab = "QIC",
    type = "l", lwd = 2, col = "gray",
    bty = "n"
)
lines(
    x = seq_len(nsims), y = qic_ar1,
    col = "firebrick", lwd = 2
)
lines(
    x = seq_len(nsims), y = qic_cs,
    col = "steelblue4", lwd = 2
)
legend_top(
    legend = c("Independence", "Exchangeable", "AR(1)"),
    col = c("gray", "steelblue4", "firebrick"),
    lwd = 2, lty = 1, title = "Working correlation structure"
)
```


#### Goodness-of-fit
```{r, echo = FALSE}
gof_indp <- rep(NA, nsims)
gof_ar1 <- rep(NA, nsims)
gof_cs <- rep(NA, nsims)
for (k in seq_len(nsims)) {
    w1 <- res_indp[[k]]$min
    w2 <- res_ar1[[k]]$min
    w3 <- res_cs[[k]]$min
    gof_indp[k] <- res_indp[[k]]$gof[w1]
    gof_ar1[k] <- res_ar1[[k]]$gof[w2]
    gof_cs[k] <- res_cs[[k]]$gof[w3]
}

plot(
    x = seq_len(nsims), y = gof_indp,
    ylim = c(1700, 4800),
    xlab = "Index", ylab = "GOF",
    type = "l", lwd = 2, col = "gray",
    bty = "n"
)
lines(
    x = seq_len(nsims), y = gof_ar1,
    col = "firebrick", lwd = 2
)
lines(
    x = seq_len(nsims), y = gof_cs,
    col = "steelblue4", lwd = 2
)
legend_top(
    legend = c("Independence", "Exchangeable", "AR(1)"),
    col = c("gray", "steelblue4", "firebrick"),
    lwd = 2, lty = 1, title = "Working correlation structure"
)
```

#### Penalty
```{r, echo = FALSE}
penalty_indp <- rep(NA, nsims)
penalty_ar1 <- rep(NA, nsims)
penalty_cs <- rep(NA, nsims)
for (k in seq_len(nsims)) {
    w1 <- res_indp[[k]]$min
    w2 <- res_ar1[[k]]$min
    w3 <- res_cs[[k]]$min
    penalty_indp[k] <- res_indp[[k]]$penalty[w1]
    penalty_ar1[k] <- res_ar1[[k]]$penalty[w2]
    penalty_cs[k] <- res_cs[[k]]$penalty[w3]
}

plot(
    x = seq_len(nsims), y = penalty_indp,
    ylim = c(5, 25),
    xlab = "Index", ylab = "Penalty",
    type = "l", lwd = 2, col = "gray",
    bty = "n"
)
lines(
    x = seq_len(nsims), y = penalty_ar1,
    col = "firebrick", lwd = 2
)
lines(
    x = seq_len(nsims), y = penalty_cs,
    col = "steelblue4", lwd = 2
)
legend_top(
    legend = c("Independence", "Exchangeable", "AR(1)"),
    col = c("gray", "steelblue4", "firebrick"),
    lwd = 2, lty = 1, title = "Working correlation structure"
)
```

### Feature selection based on QIC
For measuring the overall performance based on each working correlation structure, a function will be created called `look` that reports the number of models, where

- the number of features selected is less than the number of non-zero coefficients in the generating model (`under`), 
- only the non-zero features from the generating model were selected (`exact`), 
- the number of features selected matches the number of non-zero coefficients in the generating model; however, at least one of the selected features is NOT one of the non-zero effects in the generating model (i.e., `mis`),
- the number of features selected is greated than the number of non-zero coefficients in the generating model (`over`), and
- the number of features selected is greated than the number of non-zero coefficients in the generating model and include all the non-zero effects (`over_inc`).

```{r, echo = FALSE}
# creating a function to generate a look at the simulation results
look <- function(x) {
    under <- 0
    exact <- 0
    mis <- 0
    over <- 0
    over_inc <- 0
    for (k in seq_len(nsims)) {
        under <- under + (length(x[[k]]$vars) < l)
        exact <- exact + identical(x[[k]]$vars, w)
        mis <- mis + (!identical(x[[k]]$vars, w) & (length(x[[k]]$vars) == l))
        over <- over + (length(x[[k]]$vars) > l)
        over_inc <- over_inc + ((length(x[[k]]$vars) > l) & all(w %in% x[[k]]$vars))
    }
    return(
        data.frame(
            under = under, exact = exact,
            mis = mis, over = over,
            over_inc = over_inc
        )
    )
}
```

Using the `look` function, we have the following summary measures from the simulation set, where the model resulting in the minimum QIC value was selected as the best fitting model for each working correlation structure.
```{r, echo = FALSE}
data.frame(
    work_corr = c("Independence", "Exchangeable", "AR(1)"),
    dplyr::bind_rows(look(res_indp), look(res_cs), look(res_ar1))
)
```
